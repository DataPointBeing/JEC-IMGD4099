In truth, I had a really difficult time settling on what to do for my final. I started out by working on a dry visualizer in Seagulls for demonstrating two simple (and naive) ways to map coordinates from one polar shape to another, but it was a subject that yielded bland visual results and involved math I couldn't fully understand, so I scrapped it. From there, I decided I might be interested in tackling general, computationally-correct Voronoi tesselations (which I love as always) in a context outside of simple cellular noise, such as to make stylized stained glass windows... it's an effect I've enjoyed working on in Unreal, but where I couldn't seem to find as nice a path forward as I wanted within Seagulls and was too concerned about how well I could manage my time wracking my brain on such a complex task.

Ultimately I turned my attention back to reaction-diffusion since it was my favorite work to date in this class, and I endeavored to work on it further. I had already implemented simple color blending, a grid backdrop, and a very basic fragment shader for creating vaguely glossy effects, but all told my implementation had few sophisticated features. Bearing in mind its room for improvement I decided to use it as the starting point for my _final_ final concept, with the driving force behind working on it being to enhance the "cartoon science" appearance of the system -- almost like a science toy or a retro-styled textbook diagram.

The two explorations I honed in on were #1, interesting means of interaction, and #2, aesthetic improvement of the simulation. The latter was fairly easy: I had already dabbled with using local samples to put highlights in the right places, so I decided to implement a more advanced secondary "mode" of highighting under circumstances where large blobs of chemical B should look like rounded spheres instead of flat discs. This more focused highlight, present when there's an abundance of chemical B below and left of the target highlight spot, lent better definition to these "spheres", especially when paired with darker shadows created using a similar process sampling in the opposite direction (down and left, instead of up and right). It was a stroke of luck that the shadow behavior needed little to no tuning to work on different thicknesses of chemical B masses, as on thinner, translucent "tendrils" the mingling of dark and light colors registers to the eye not like shadow but gem-, gelatin-, or fluid-like contrast, lending a more striking shiny, biological look to the reaction at large. The only issue was some mild self-shadow artifacting due to confusion by adjacent objects; to address this, I let the backup option (in case the shadowing conditions were not met) be to sample the color where the original distance reading was being taken and blend evenly it with the actual color; in essence, this produces surface reflections of neighboring colors that add even more visual interest to the clusters, while not interrupting the interiors of of homogenous "blobs" where reflections shouldn't appear (because the "outside" color sample and the actual color being blended are already identical). I also tuned the random color generator somewhat to allow for a better variety of colors while still keeping value within a consistent, gentle range.

Implementing novel means of interaction posed more issues for me. My main idea saw me using camera input to seed the "petri dish" with a series of blobs in the image of the viewer, or on a subtler level show the user's reflection in the blobs, making it appear as if they're looking down into them. I ended up moving away from these as I regrettably could not get camera input to coexist with my compute shader... I'm still unsure why. As a substitute for the seeding idea, I created a small system for seeding the board with colorful cellular noise instead; had I been able to achieve camera functionality, a camera sample would simply have replaced the tesselation. From there I had some interest in trying to instead port the simulation to mobile, using tilt to influence the flow of the chemicals, but given the limited time I had left and issues running Seagulls on my phone this also proved more than I could manage.

But inspired by Milo's method of using a balance board's alignment to interfere with a Laplace transform from his presentation, I came up with something. I implemented a similar convulution to his own, but using scaled **scroll input** by the user. Reflected also by a jittery offset in the backdrop during scrolling, I aimed to evoke the effect of "smearing" reagants or shaking the petri dish via scrolling, and found it successful. Light scrolling in any direction begins to bias growth along that axis, while fast scrolling disrupts the entire screen with ripples. In the course of recording the video provided with this description, I ran into an interesting (accidental) consequence of this effect: in rare cases of interruption, scrolling may not register to have stopped, as in when I inadvertently skipped back a page and then returned to the simulation. With the waves proceeding on their own, I took the opportunity to place down new masses of reagant to see how they'd interact, and marveled at the way they were swept away in the nonstop motion. I subsequently changed the CSS to prevent such easy interruption by trackpad navigation commands, but am still glad I immortalized the glitch in my clip.

![Screenshot 2023-10-12 001044](https://github.com/DataPointBeing/JEC-IMGD4099/assets/39743767/2dc44c6e-8df8-45f7-8d9c-d77372c8ab30)
![Screenshot 2023-10-12 000335](https://github.com/DataPointBeing/JEC-IMGD4099/assets/39743767/f8711ca3-cb44-45bd-b49f-4293bf3310e5)
![Screenshot 2023-10-11 071959](https://github.com/DataPointBeing/JEC-IMGD4099/assets/39743767/7f1cc629-9aec-4a76-b197-70cd863a1f11)
![image](https://github.com/DataPointBeing/JEC-IMGD4099/assets/39743767/23373b20-575a-44df-bf2f-dcb3a33c86d1)
![image](https://github.com/DataPointBeing/JEC-IMGD4099/assets/39743767/40e0abb3-3389-4aa1-a9cb-c8e79d2451a0)


